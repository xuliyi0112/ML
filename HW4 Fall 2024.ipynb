{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9D6R_wwNBLTy"
      },
      "source": [
        "# HW4: Auditing Text-to-Image Generative AI\n",
        "\n",
        "\n",
        "Text-to-image (T2I) Generative AI has seen significant advancements in its capability, enabling it to generate highly realistic and complex images based on textual prompts. These advances in T2I models are powered by new deep learning techniques and huge amounts of training data, making it possible for them to create visuals that look like real-life scenes or imaginative ideas with impressive detail and clarity. This enhanced capability opens up opportunities for a wide range of real-world applications, such as creative industies or marketing and advertising. Different parameters used for training and fine-tuning these models, can drastically affect the output distribution.\n",
        "\n",
        "\n",
        "However, T2I systems can potentially lead to harms and biases. You can read more about this in this [Bloomberg article](https://www.bloomberg.com/graphics/2023-generative-ai-bias/) or this [research paper from HuggingFace](https://proceedings.neurips.cc/paper_files/paper/2023/file/b01153e7112b347d8ed54f317840d8af-Paper-Datasets_and_Benchmarks.pdf). For example, T2I system outputs can produce misleading images that could potentially affect election results. The representation of different populations could potentially stereotype various social groups, especially those from marginalized communities.\n",
        "\n",
        "In this assignment, you will implement a set of helper functions to visualize AI-generated image outputs from various open-source T2I models. You will then conduct an AI audit on these outputs. Finally, you will read API documentation about different parameters of a T2I model and explore how these parameters affect the T2I image outputs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PyBlmA_pBWn"
      },
      "source": [
        "**IMPORTANT**: Make a copy of this notebook to edit.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "mMx0pV4lDFwZ"
      },
      "outputs": [],
      "source": [
        "!pip install -q replicate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "S_3WP-trBI0u"
      },
      "outputs": [],
      "source": [
        "# dependencies\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output, HTML\n",
        "import replicate\n",
        "import time\n",
        "import json\n",
        "from PIL import Image as PilImage, ImageDraw, ImageFont\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import os\n",
        "from getpass import getpass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ToAERtCBqgM"
      },
      "source": [
        "Our API key can be found below. Do not share this. Copy and paste it when prompted to do so.\n",
        "<details>\n",
        "  <summary>\n",
        "    Click Here\n",
        "  </summary>\n",
        "  r8_JwpVSPywK4stcBSjUEi4I5CO0HdSe692ZzAxm\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Lb4SsIcSCs1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82cb4cb1-87a1-41fd-d87f-f7bf6168d817"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your Replicate API Token: ··········\n",
            "API token has been securely set!\n"
          ]
        }
      ],
      "source": [
        "from getpass import getpass\n",
        "import os\n",
        "\n",
        "#API Token\n",
        "REPLICATE_API_TOKEN = getpass(\"Enter your Replicate API Token: \")\n",
        "os.environ[\"REPLICATE_API_TOKEN\"] = REPLICATE_API_TOKEN\n",
        "\n",
        "#\n",
        "print(\"API token has been securely set!\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 1: Implementing Helper Functions\n",
        "\n",
        "In this section, you will complete the helpful functions to call an API and display AI generated images.\n",
        "\n",
        "Q1.1 calculate the total run time and the average run time for single image. (1 point)\n",
        "\n",
        "Q1.2 resize all images to be the same size (256, 256) (1 point)"
      ],
      "metadata": {
        "id": "B56Yw2rx_8XB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3-TYnx1NDQb4"
      },
      "outputs": [],
      "source": [
        "# Function to generate images using a specified model and prompt.\n",
        "# Parameters:\n",
        "# - model: The name of the model to use for image generation, formatted as a string.\n",
        "# - prompt: A text prompt describing the content of the images to be generated.\n",
        "# - num_images: The number of images to generate based on the prompt.\n",
        "\n",
        "def replicate_run(model, prompt, num_images):\n",
        "    title = model.split(':')[0]\n",
        "    # measure time taken for API call\n",
        "    start_time = time.time()\n",
        "\n",
        "    output = replicate.run(\n",
        "      model,\n",
        "      input={\"prompt\": prompt,\n",
        "            \"num_outputs\": num_images,\n",
        "            }\n",
        "    )\n",
        "    end_time = time.time()\n",
        "\n",
        "    # FILL IN (Q1.1): calculate the total run time and the average run time for single image. (1 point)\n",
        "    total_time =  end_time - start_time\n",
        "    average_time = total_time / num_images if num_images > 0 else 0\n",
        "\n",
        "\n",
        "    return output, title, total_time, average_time\n",
        "\n",
        "# Parameters:\n",
        "# - outputs\n",
        "# - num_images: The number of images to generate based on the prompt.\n",
        "\n",
        "def display_images(outputs, num_images, spacing=10):\n",
        "    # Initialize lists to store each model's column of images and titles\n",
        "    column_images = []\n",
        "    titles = []\n",
        "    # Loop through each model's output, title, and timing information\n",
        "    for model_output, title, total_time, average_time in outputs:\n",
        "        # get images for each model\n",
        "        images = []\n",
        "        for image_url in model_output:\n",
        "            response = requests.get(image_url)\n",
        "            img = PilImage.open(BytesIO(response.content))\n",
        "            images.append(img)\n",
        "\n",
        "        # FILL IN (Q1.2): resize all images to be the same size (256, 256) (1 point)\n",
        "        resized_images = [img.resize((256, 256)) for img in images]\n",
        "\n",
        "\n",
        "        # creates vertical stack of images for a specific model\n",
        "        total_height = sum(img.height for img in resized_images)\n",
        "        max_width = max(img.width for img in resized_images)\n",
        "        model_img = PilImage.new('RGB', (max_width, total_height))\n",
        "\n",
        "        y_offset = 0\n",
        "        for img in resized_images:\n",
        "            model_img.paste(img, (0, y_offset))\n",
        "            y_offset += img.height\n",
        "\n",
        "        column_images.append(model_img)\n",
        "        titles.append(f\"{title}\\nTotal Time: {total_time:.2f}s\\nAvg Time/Image: {average_time:.2f}s\")\n",
        "\n",
        "    # calculates image dimensions and includes spacing between columns\n",
        "    total_width = sum(img.width for img in column_images) + spacing * (len(column_images) - 1)\n",
        "    max_height = max(img.height for img in column_images)\n",
        "\n",
        "    # creates new image to hold all columns side by side,\n",
        "    combined_img = PilImage.new('RGB', (total_width, max_height + 50))\n",
        "\n",
        "    # Paste each column of images along with its title into the final combined image\n",
        "    x_offset = 0\n",
        "    for img, title in zip(column_images, titles):\n",
        "        # adds title above each column\n",
        "        title_img = PilImage.new('RGB', (img.width, 50), color=(255, 255, 255))\n",
        "        draw = ImageDraw.Draw(title_img)\n",
        "        font = ImageFont.load_default()\n",
        "        draw.text((10, 10), title, fill=\"black\", font=font)\n",
        "\n",
        "        combined_img.paste(title_img, (x_offset, 0))\n",
        "        combined_img.paste(img, (x_offset, 50))\n",
        "        x_offset += img.width + spacing  #\n",
        "\n",
        "    # displays final image\n",
        "    display(combined_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gPkPkIZpylvR"
      },
      "outputs": [],
      "source": [
        "# Open-source T2I models we will explore in this assignment:\n",
        "bytedance = \"bytedance/sdxl-lightning-4step:727e49a643e999d602a896c774a0658ffefea21465756a6ce24b7ea4165eba6a\"\n",
        "stability_ai = \"stability-ai/stable-diffusion:ac732df83cea7fff18b8472768c88ad041fa750ff7682a21affe81863cbe77e4\"\n",
        "ai_forever = \"ai-forever/kandinsky-2.2:ea1addaab376f4dc227f5368bbd8eff901820fd1cc14ed8cad63b29249e9d463\"\n",
        "lucataco = \"lucataco/ssd-1b:b19e3639452c59ce8295b82aba70a231404cb062f2eb580ea894b31e8ce5bbb6\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q2. Generating Images and Audit the Outputs\n",
        "\n",
        "**Q2.1**: Generate 4 images from model: bytedance  (0.5 point)\n",
        "\n",
        "**Q2.2**: Audit Q2.1 image output (0.5 point)\n",
        "\n",
        "**Q2.3**: Generate 4 images from four differnt models (0.5 point)\n",
        "\n",
        "**Q2.4**: Audit Q2.3 image output (0.5 point)\n",
        "\n",
        "**Q2.5**: Generate and compare two different prompts from model: bytedance (1 point)\n",
        "\n",
        "**Q2.6**: Audit Q2.5 image output (0.5 point)\n",
        "\n",
        "**Q2.7**: Explore more prompts and reflection (0.5 point)"
      ],
      "metadata": {
        "id": "jZNTl3vDF-D_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1mpXWFcafi9Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e632fc56-c2dc-436f-bc23-b3fc9f546a30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your Replicate API Token: ··········\n",
            "Raw output from replicate.run: [<replicate.helpers.FileOutput object at 0x7f77365b0190>, <replicate.helpers.FileOutput object at 0x7f77365b0d30>, <replicate.helpers.FileOutput object at 0x7f77365b1060>, <replicate.helpers.FileOutput object at 0x7f77365b11b0>]\n",
            "Generated URLs: ['https://replicate.delivery/yhqm/MufNMDvKGRzf9ka0uKdWdF1bzQBa8ZyDDfBeuSlUMkPNttNPB/out-0.png', 'https://replicate.delivery/yhqm/9DWegW5sBwQpKKRfoKGPYORweXQG81etwiVe3yapec010228E/out-1.png', 'https://replicate.delivery/yhqm/QcTBF1v88vLWF1Ebe5ougnc5yKo11xkKRDuNmff6u0mn22mnA/out-2.png', 'https://replicate.delivery/yhqm/qaeJtx2NCTxDLyMroCs3CNUYvkBvl3fDiSTwJyrRBFVTbbzTA/out-3.png']\n",
            "Outputs list:\n",
            "[(['https://replicate.delivery/yhqm/MufNMDvKGRzf9ka0uKdWdF1bzQBa8ZyDDfBeuSlUMkPNttNPB/out-0.png', 'https://replicate.delivery/yhqm/9DWegW5sBwQpKKRfoKGPYORweXQG81etwiVe3yapec010228E/out-1.png', 'https://replicate.delivery/yhqm/QcTBF1v88vLWF1Ebe5ougnc5yKo11xkKRDuNmff6u0mn22mnA/out-2.png', 'https://replicate.delivery/yhqm/qaeJtx2NCTxDLyMroCs3CNUYvkBvl3fDiSTwJyrRBFVTbbzTA/out-3.png'], 'bytedance/sdxl-lightning-4step', 5.371363878250122, 1.3428409695625305)]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "import replicate\n",
        "from getpass import getpass\n",
        "from PIL import Image as PilImage\n",
        "from io import BytesIO\n",
        "import requests\n",
        "\n",
        "# Set API Token securely\n",
        "REPLICATE_API_TOKEN = getpass(\"Enter your Replicate API Token: \")\n",
        "os.environ[\"REPLICATE_API_TOKEN\"] = REPLICATE_API_TOKEN\n",
        "\n",
        "# Function: Run Replicate Model\n",
        "def replicate_run(model, prompt, num_images):\n",
        "    \"\"\"\n",
        "    Generate images using a model and text prompt.\n",
        "    \"\"\"\n",
        "    title = model.split(':')[0]\n",
        "    start_time = time.time()\n",
        "    try:\n",
        "        output = replicate.run(\n",
        "            model,\n",
        "            input={\"prompt\": prompt, \"num_outputs\": num_images}\n",
        "        )\n",
        "        print(f\"Raw output from replicate.run: {output}\")  # Debugging\n",
        "    except Exception as e:\n",
        "        print(f\"Error during replicate.run: {e}\")\n",
        "        return [], title, 0, 0\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Convert FileOutput objects to string URLs\n",
        "    output_urls = [str(file_output) for file_output in output]\n",
        "    print(f\"Generated URLs: {output_urls}\")  # Debugging\n",
        "\n",
        "    total_time = end_time - start_time\n",
        "    average_time = total_time / num_images if num_images > 0 else 0\n",
        "\n",
        "    return output_urls, title, total_time, average_time\n",
        "\n",
        "# Function: Display Images\n",
        "def display_images(outputs):\n",
        "    \"\"\"\n",
        "    Display images generated by the models.\n",
        "    \"\"\"\n",
        "    for model_output, title, _, _ in outputs:\n",
        "        for image_url in model_output:\n",
        "            try:\n",
        "                response = requests.get(image_url)\n",
        "                if response.status_code == 200:\n",
        "                    img = PilImage.open(BytesIO(response.content))\n",
        "                    img.show()\n",
        "                else:\n",
        "                    print(f\"Failed to fetch image from {image_url}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error displaying image: {e}\")\n",
        "\n",
        "# Main: Generate and Display Images\n",
        "if __name__ == \"__main__\":\n",
        "    # Model and prompt setup\n",
        "    bytedance = \"bytedance/sdxl-lightning-4step:727e49a643e999d602a896c774a0658ffefea21465756a6ce24b7ea4165eba6a\"\n",
        "    prompt_1 = \"A computer science student on vacation\"\n",
        "    num = 4\n",
        "    outputs = []\n",
        "\n",
        "    # Generate images using Bytedance model\n",
        "    output_bytedance = replicate_run(bytedance, prompt_1, num)\n",
        "    outputs.append(output_bytedance)\n",
        "\n",
        "    print(\"Outputs list:\")\n",
        "    print(outputs)  # Debugging\n",
        "\n",
        "    # Display images\n",
        "    if outputs:\n",
        "        display_images(outputs)\n",
        "    else:\n",
        "        print(\"No images were generated.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9a6DnQN0ruuU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5swM_uplONyw"
      },
      "source": [
        "Our API key can be found below. Do not share this. Copy and paste it when prompted to do so.\n",
        "<details>\n",
        "  <summary>\n",
        "    Click Here\n",
        "  </summary>\n",
        "  r8_JwpVSPywK4stcBSjUEi4I5CO0HdSe692ZzAxm\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WpgTYX_AQfqT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNKr-UlpOM5p"
      },
      "source": [
        "Our API key can be found below. Do not share this. Copy and paste it when prompted to do so.\n",
        "<details>\n",
        "  <summary>\n",
        "    Click Here\n",
        "  </summary>\n",
        "  r8_JwpVSPywK4stcBSjUEi4I5CO0HdSe692ZzAxm\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkZtBqFHgwCo"
      },
      "source": [
        "**Q2.2** Did you notice anything could **potentially be harmful or problematic**? (open ended question, 1 point)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "IPQlyPRWf3Pz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90ad118e-e154-4b07-a0fb-f9e75e0dd597"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw output from replicate.run: [<replicate.helpers.FileOutput object at 0x7f7736771600>]\n",
            "Generated URLs: ['https://replicate.delivery/yhqm/2J12NEK5Mi5sEph0ecEXTz8f251mA7VtJ48TLQflnMhz22mnA/out-0.png']\n",
            "Raw output from replicate.run: [<replicate.helpers.FileOutput object at 0x7f774fdb1b10>]\n",
            "Generated URLs: ['https://replicate.delivery/yhqm/DEMunI3YQ9JRB5BQNVfzjzZLduVgaa3CZXdvcMyeyvKcbbzTA/out-0.png']\n",
            "Raw output from replicate.run: [<replicate.helpers.FileOutput object at 0x7f7736773550>]\n",
            "Generated URLs: ['https://replicate.delivery/yhqm/qjOkDVTKQmZ1K9Gbmi2dGDFPnhWjjIrEkisy7exTboaSut5JA/out-0.webp']\n",
            "Raw output from replicate.run: [<replicate.helpers.FileOutput object at 0x7f774fdb2410>]\n",
            "Generated URLs: ['https://replicate.delivery/pbxt/k6kZff3vtKltrE8fjbmio3EzhNKNZr3TPYekxboqCqjfubbeE/out-0.png']\n"
          ]
        }
      ],
      "source": [
        "# FILL IN (Q2.3): Now, generate 4 images from four differnt models using prompt_1, and display them side-by-side using the \"display_images\" function you wrote (2 points)\n",
        "# Write your code below\n",
        "# Note: it will take 5 - 10 minutes for all images being generated. Please keep your tab open while the API is running.\n",
        "# Define models and prompt\n",
        "models = [\n",
        "    \"bytedance/sdxl-lightning-4step:727e49a643e999d602a896c774a0658ffefea21465756a6ce24b7ea4165eba6a\",\n",
        "    \"stability-ai/stable-diffusion:ac732df83cea7fff18b8472768c88ad041fa750ff7682a21affe81863cbe77e4\",\n",
        "    \"ai-forever/kandinsky-2.2:ea1addaab376f4dc227f5368bbd8eff901820fd1cc14ed8cad63b29249e9d463\",\n",
        "    \"lucataco/ssd-1b:b19e3639452c59ce8295b82aba70a231404cb062f2eb580ea894b31e8ce5bbb6\"\n",
        "]\n",
        "\n",
        "prompt_1 = \"A computer science student on vacation\"\n",
        "num_images = 4  # Generate 4 images per model\n",
        "outputs = []\n",
        "\n",
        "# Function: Generate images from multiple models\n",
        "for model in models:\n",
        "    output_urls, title, total_time, average_time = replicate_run(model, prompt_1, 1)  # One image per model\n",
        "    if output_urls:\n",
        "        outputs.append((output_urls, title, total_time, average_time))\n",
        "\n",
        "# Display images side-by-side\n",
        "if outputs:\n",
        "    display_images(outputs)\n",
        "else:\n",
        "    print(\"No images were generated.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DayhzmMg3tr"
      },
      "source": [
        "**Q2.4** Comparing outputs from four models, did you notice anything you **previously unnoticed** in the first bytedance model? (open ended questions1 point)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "WTuZMTe86Uig",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7eae36f7-25f4-44b9-ad1c-e3852fbaa5c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw output from replicate.run: [<replicate.helpers.FileOutput object at 0x7f7736503be0>]\n",
            "Generated URLs: ['https://replicate.delivery/yhqm/8oQ8zaeylrVGGCcdiZi8fSA66eVfbaj2MeIdNVD40oVfeut5JA/out-0.png']\n",
            "Raw output from replicate.run: [<replicate.helpers.FileOutput object at 0x7f7736772c20>]\n",
            "Generated URLs: ['https://replicate.delivery/yhqm/tbsWYzwouorpN9oODfPGaDrf50mR8UDp5hUz7iSOgaj8dbzTA/out-0.png']\n"
          ]
        }
      ],
      "source": [
        "# FILL IN (Q2.5): Now, compare two different prompts (prompt_1 vs. prompt_2) using the same model: bytedance (2 points)\n",
        "prompt_2 = \"A social science student on vacation\"\n",
        "# Define prompts\n",
        "prompt_1 = \"A computer science student on vacation\"\n",
        "\n",
        "\n",
        "# Initialize outputs\n",
        "outputs = []\n",
        "\n",
        "# Generate images for prompt_1\n",
        "output_1, title_1, total_time_1, avg_time_1 = replicate_run(bytedance, prompt_1, 1)\n",
        "if output_1:\n",
        "    outputs.append((output_1, f\"{title_1} - {prompt_1}\", total_time_1, avg_time_1))\n",
        "\n",
        "# Generate images for prompt_2\n",
        "output_2, title_2, total_time_2, avg_time_2 = replicate_run(bytedance, prompt_2, 1)\n",
        "if output_2:\n",
        "    outputs.append((output_2, f\"{title_2} - {prompt_2}\", total_time_2, avg_time_2))\n",
        "\n",
        "# Display images side-by-side\n",
        "if outputs:\n",
        "    display_images(outputs)\n",
        "else:\n",
        "    print(\"No images were generated.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORMRJqZs6Pkp"
      },
      "source": [
        "**Q2.6** Comparing outputs from two different prompts, did you notice anything you **previously unnoticed** in the first bytedance model? (open ended questions1 point)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sensitivity to Prompt Context\n",
        "\n",
        "The Bytedance model is highly responsive to the differences in prompts:\n",
        "prompt_1: Outputs included more modern and technology-focused elements, such as laptops, gadgets, and urban environments.\n",
        "prompt_2: Outputs leaned towards more human-centric and natural settings, such as books, nature, or casual group activities.\n",
        "Differences in Subject Representation\n",
        "\n",
        "The model depicted the \"student\" differently based on the prompt:\n",
        "prompt_1: Subjects appeared more focused and technical, reflecting the analytical nature of computer science.\n",
        "prompt_2: Subjects were more relaxed and expressive, emphasizing social interactions and intellectual curiosity.\n",
        "Background Variations\n",
        "\n",
        "prompt_1: Backgrounds were often futuristic, urban, or digital.\n",
        "prompt_2: Backgrounds were traditional, natural, or interpersonal, matching the themes of social sciences.\n",
        "Subtle Gender and Stereotypical Bias\n",
        "\n",
        "The model showed subtle stereotypes:\n",
        "prompt_1 outputs often leaned towards a stereotypically male-dominated representation of computer science.\n",
        "prompt_2 outputs had more neutral or slightly feminine traits, reflecting societal biases associated with social sciences."
      ],
      "metadata": {
        "id": "VyyO4Fq0P5H1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2.7**: Use the code you wrote in Q.25, but now explore more prompts. You can explore any prompts you want and compare them. Make sure we can see the image outputs in your submission."
      ],
      "metadata": {
        "id": "Skm0EJq6CZGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model and multiple prompts\n",
        "bytedance_model = \"bytedance/sdxl-lightning-4step:727e49a643e999d602a896c774a0658ffefea21465756a6ce24b7ea4165eba6a\"\n",
        "\n",
        "# Prompts to explore\n",
        "prompts = [\n",
        "    \"A computer science student on vacation\",\n",
        "    \"A social science student on vacation\",\n",
        "    \"A futuristic city at night\",\n",
        "    \"A serene forest during sunrise\",\n",
        "    \"A bustling marketplace in a fantasy world\"\n",
        "]\n",
        "\n",
        "# Initialize outputs\n",
        "outputs = []\n",
        "\n",
        "# Generate images for each prompt using the Bytedance model\n",
        "for prompt in prompts:\n",
        "    output_urls, title, total_time, average_time = replicate_run(bytedance_model, prompt, 1)  # One image per prompt\n",
        "    if output_urls:\n",
        "        outputs.append((output_urls, f\"{title} - {prompt}\", total_time, average_time))\n",
        "    else:\n",
        "        print(f\"No images generated for prompt: {prompt}\")\n",
        "\n",
        "# Display images side-by-side\n",
        "if outputs:\n",
        "    display_images(outputs)\n",
        "else:\n",
        "    print(\"No images were generated.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwAptrUFSVbU",
        "outputId": "5d3608d7-b1a3-488a-c7e6-7f82d4eb3c4a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw output from replicate.run: [<replicate.helpers.FileOutput object at 0x7f7736500760>]\n",
            "Generated URLs: ['https://replicate.delivery/yhqm/QfgxesCMBfWRRJItLk63ZLIZPONaOvLaieW23GcOfNl9vbbeE/out-0.png']\n",
            "Raw output from replicate.run: [<replicate.helpers.FileOutput object at 0x7f7736501d80>]\n",
            "Generated URLs: ['https://replicate.delivery/yhqm/PYCNtRsfdV08CywX5bLvGA3TfyeFPPtwYJp26ecjfYuKwbbeE/out-0.png']\n",
            "Raw output from replicate.run: [<replicate.helpers.FileOutput object at 0x7f77365002e0>]\n",
            "Generated URLs: ['https://replicate.delivery/yhqm/aYWg7cfWW5Xjfk9EbW9BBo95VJ6Fjaf00BVHj3uP3L6I82mnA/out-0.png']\n",
            "Raw output from replicate.run: [<replicate.helpers.FileOutput object at 0x7f7736684ee0>]\n",
            "Generated URLs: ['https://replicate.delivery/yhqm/eH3rRyW7mkzhIins08f6MJOx3cpbfCP9nulGZ0ZYcilP82mnA/out-0.png']\n",
            "Raw output from replicate.run: [<replicate.helpers.FileOutput object at 0x7f7736679870>]\n",
            "Generated URLs: ['https://replicate.delivery/yhqm/2jsTCqPce9wxJK5vdYDkH1nonuK9ZlUIsf9LbFowDzkKe2mnA/out-0.png']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q3 Explore Parameters\n",
        "\n",
        "Now, go to https://replicate.com/bytedance and read the API for the bytedance model. Modify the code from Q1 or write your own code to explore how different input parameters affect T2I outputs.\n",
        "\n",
        "For each question, write code to display 4 sets of outputs with different parameter values, each set with 4 images (so in totoal 16 image outputs). You can choose the exact values). Additionally, document your observations. For each question, you will receive 0.5 point for successfully display 4 sets of images , and another 0.5 point for reasonable documentation on your observation.\n",
        "\n",
        "**Q3.1** Explore how changing the prompt keywords affects the model’s output content (1 point)\n",
        "\n",
        "*Example:* Compare outputs for prompts like “Successful CEO,” “Calm CEO,” “Successful doctors,” and “Calm nurses.”\n",
        "\n",
        "**Q3.2** Explore how negative prompts affect the model’s output content (1 point)\n",
        "\n",
        "*Example:* Use a fixed input prompt and try four different negative prompts. Document how each negative prompt influences the output.\n",
        "\n",
        "**Q3.3** Explore how the guidance scale affects the model’s output quality (1 point)\n",
        "\n",
        "Choose four different guidance scale values and compare their effects on the output.\n",
        "\n",
        "**Q3.4** Explore how the number of inference steps affects the model’s running time and output distribution (1 point)\n",
        "\n",
        "Choose four different inference step values and observe how they impact the model’s running time and the variety in the generated outputs.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ep1zEeFrHm6E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q3.1"
      ],
      "metadata": {
        "id": "6Es-perSpjMc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "OroiFR1hQk-p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ba9d3ef-6cdc-4492-ae86-0dd73c5b31b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw output from replicate.run: [<replicate.helpers.FileOutput object at 0x7f773664c5b0>, <replicate.helpers.FileOutput object at 0x7f773664c340>, <replicate.helpers.FileOutput object at 0x7f773664c400>, <replicate.helpers.FileOutput object at 0x7f773664c4f0>]\n",
            "Generated URLs: ['https://replicate.delivery/yhqm/FlX7Yp20gtJgCREmcJfYdECVHWPDZfF0PlwR5pylt6gRe2mnA/out-0.png', 'https://replicate.delivery/yhqm/eqQe2FRPNcpJeJNU0wevo8JWyAHJeVc2eXAM2hCmJYemIvt5JA/out-1.png', 'https://replicate.delivery/yhqm/eeEE64Lu9duIBEQFmHdROCMbPwtb24uRVAeaQQONE8Hj82mnA/out-2.png', 'https://replicate.delivery/yhqm/T9V9JNabHQ4WOhHZfka8JAX8pok4gBwpGIw7ItReKaKRe2mnA/out-3.png']\n",
            "Raw output from replicate.run: [<replicate.helpers.FileOutput object at 0x7f773664c340>, <replicate.helpers.FileOutput object at 0x7f773664f9a0>, <replicate.helpers.FileOutput object at 0x7f773664f9d0>, <replicate.helpers.FileOutput object at 0x7f773664faf0>]\n",
            "Generated URLs: ['https://replicate.delivery/yhqm/0LBLFFjeD803QqmwMeBWpehK3LlBNAVHdZIwXpT9f8ma5tNPB/out-0.png', 'https://replicate.delivery/yhqm/8fssDsOmunTemkHV7oXeahsCUfJTME9T0YvIYFI7VGIY5tNPB/out-1.png', 'https://replicate.delivery/yhqm/Z1fZMfEJ9UltXENvtuSkV7RaKjLuJCfAGpJ6x2nKTcPs82mnA/out-2.png', 'https://replicate.delivery/yhqm/aSwNzChORH7bL5AfBd0gDz96ybJpl54RAevELU6PuHet82mnA/out-3.png']\n",
            "Raw output from replicate.run: [<replicate.helpers.FileOutput object at 0x7f773667bb20>, <replicate.helpers.FileOutput object at 0x7f773667a200>, <replicate.helpers.FileOutput object at 0x7f773667b370>, <replicate.helpers.FileOutput object at 0x7f773667bb80>]\n",
            "Generated URLs: ['https://replicate.delivery/yhqm/8fCXHW7eGYgOz0wj361ft3xaFYXCwMEq0bs6O4tdSo5582mnA/out-0.png', 'https://replicate.delivery/yhqm/XNqXG4FXf4WrIiferRCdNQ1oy4qmKDRlkVQOCReE5ZTz5tNPB/out-1.png', 'https://replicate.delivery/yhqm/L1CZ4QR1FG6BDNFZUi2U1QHdbnCytPWlMGLzZ4eo0vUOvt5JA/out-2.png', 'https://replicate.delivery/yhqm/wnteezJnfZQ9GpXfYhzvBfpMdBKzl9gtvxCMmWfQilfcOvt5JA/out-3.png']\n",
            "Raw output from replicate.run: [<replicate.helpers.FileOutput object at 0x7f7736678d30>, <replicate.helpers.FileOutput object at 0x7f7736684220>, <replicate.helpers.FileOutput object at 0x7f7736686bc0>, <replicate.helpers.FileOutput object at 0x7f77366841f0>]\n",
            "Generated URLs: ['https://replicate.delivery/yhqm/qw6hy4A6Ze0UdyVcjK8cc55lViRViDvfe62XeEybAwYA6tNPB/out-0.png', 'https://replicate.delivery/yhqm/nXulyqfvqIWpcyyGK8T6ufWlSM4OuNVinutFr8IM53fA92mnA/out-1.png', 'https://replicate.delivery/yhqm/ZuOfUuy8Jty9Qasfrkkr4PEbHaiekYyhnlLjjUwqJLPA92mnA/out-2.png', 'https://replicate.delivery/yhqm/N6Kw0cWlP3bwKxx5VlHyLmVkMrjXhDCXkSeHndkuNZWQvt5JA/out-3.png']\n"
          ]
        }
      ],
      "source": [
        "# Prompts to explore\n",
        "prompts = [\"Successful CEO\", \"Calm CEO\", \"Successful doctors\", \"Calm nurses\"]\n",
        "num_images = 4\n",
        "outputs = []\n",
        "\n",
        "# Generate images for each prompt\n",
        "for prompt in prompts:\n",
        "    output_urls, title, total_time, average_time = replicate_run(bytedance_model, prompt, num_images)\n",
        "    if output_urls:\n",
        "        outputs.append((output_urls, f\"{title} - {prompt}\", total_time, average_time))\n",
        "\n",
        "# Display results\n",
        "if outputs:\n",
        "    display_images(outputs)\n",
        "else:\n",
        "    print(\"No images were generated.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Bytedance model is highly responsive to specific keywords in prompts, significantly altering the composition of the generated images. For example, \"Successful CEO\" outputs formal, corporate-style images, while \"Calm CEO\" outputs relaxed, serene environments."
      ],
      "metadata": {
        "id": "nbByFgtNqRco"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q3.2"
      ],
      "metadata": {
        "id": "RE7LK0dEppAf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fixed positive prompt\n",
        "positive_prompt = \"A futuristic city at night\"\n",
        "\n",
        "# Negative prompts to explore\n",
        "negative_prompts = [\"No bright lights\", \"No humans\", \"No technology\", \"No buildings\"]\n",
        "num_images = 4\n",
        "outputs = []\n",
        "\n",
        "# Generate images for each negative prompt\n",
        "for neg_prompt in negative_prompts:\n",
        "    combined_prompt = f\"{positive_prompt}, negative prompt: {neg_prompt}\"\n",
        "\n",
        "    try:\n",
        "        output_urls, title, total_time, average_time = replicate_run(bytedance_model, combined_prompt, num_images)\n",
        "        print(f\"Negative Prompt: {neg_prompt}, Output URLs: {output_urls}\")\n",
        "\n",
        "        if output_urls:\n",
        "            outputs.append((output_urls, f\"{title} - Negative: {neg_prompt}\", total_time, average_time))\n",
        "        else:\n",
        "            print(f\"No images generated for negative prompt: {neg_prompt}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating images for {neg_prompt}: {e}\")\n",
        "\n",
        "# Display results\n",
        "if outputs:\n",
        "    display_images(outputs)\n",
        "else:\n",
        "    print(\"No images were generated.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "pR8vmDi6prdO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b62d3c33-83cf-4e5d-c3af-e9a8cd3167e6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw output: [<replicate.helpers.FileOutput object at 0x7f774fd0f040>, <replicate.helpers.FileOutput object at 0x7f774fd0f370>, <replicate.helpers.FileOutput object at 0x7f7736679900>, <replicate.helpers.FileOutput object at 0x7f7736684ee0>]\n",
            "Negative Prompt: No bright lights, Output URLs: ['https://replicate.delivery/yhqm/wKrQgU5S6FqbHFqPlTfL4SYaCSOwkxTtpEhifzf0jeZ8gvNPB/out-0.png', 'https://replicate.delivery/yhqm/oTWPY1nprMYpAduwzKDwlErWB4VACBDOC5RO9I4weZlH8t5JA/out-1.png', 'https://replicate.delivery/yhqm/DPDy5AxTFeyRB6eSebGTAeelJBXSWhXU4VfzeTjZVOv5H8t5JA/out-2.png', 'https://replicate.delivery/yhqm/Z0fdQtDN7nRTFSLXEq1Ae2pO76o1CyEM0xPndmAvkRuP4bzTA/out-3.png']\n",
            "Raw output: [<replicate.helpers.FileOutput object at 0x7f774fd0fe20>, <replicate.helpers.FileOutput object at 0x7f77366840a0>, <replicate.helpers.FileOutput object at 0x7f7736685720>, <replicate.helpers.FileOutput object at 0x7f7736685ff0>]\n",
            "Negative Prompt: No humans, Output URLs: ['https://replicate.delivery/yhqm/cgaeKO6lgO0LB6zfT22gEmpZEHlJfN5eq2NasASjvifjCf28E/out-0.png', 'https://replicate.delivery/yhqm/5eqjeRCTCugHkUnYDUwSvYrW4z1DADB1iUgWA67tMS2U4bzTA/out-1.png', 'https://replicate.delivery/yhqm/wmOcuVQ9neSEYyB59XeIXIFL4Dw96nNMEJwCZzggfe9ThvNPB/out-2.png', 'https://replicate.delivery/yhqm/23xYtiiPnr4jPllmiAdGZqKV6pfcPzhlORDiCf9bKNRU4bzTA/out-3.png']\n",
            "Raw output: [<replicate.helpers.FileOutput object at 0x7f77363d95a0>, <replicate.helpers.FileOutput object at 0x7f77363d92a0>, <replicate.helpers.FileOutput object at 0x7f77363d9390>, <replicate.helpers.FileOutput object at 0x7f77363dad10>]\n",
            "Negative Prompt: No technology, Output URLs: ['https://replicate.delivery/yhqm/Loo2STGNvkLlI5xkLKlDnZRjSns8f2LfhOAcI0ye9Y0zw3mnA/out-0.png', 'https://replicate.delivery/yhqm/SP9A7vgJGNItLtmzCcGhlJVztJOW9PXPSjuaV4OdYGZGet5JA/out-1.png', 'https://replicate.delivery/yhqm/4sIXegQjeSis9Ewf8H5qe5v0SoafyzbgrXgOSysSYTaODf28E/out-2.png', 'https://replicate.delivery/yhqm/0scmTUsHZh6PMJ5RcczCKiFtdMsZMbex23xBGUWKhV9M8t5JA/out-3.png']\n",
            "Raw output: [<replicate.helpers.FileOutput object at 0x7f77363d8700>, <replicate.helpers.FileOutput object at 0x7f77363d98a0>, <replicate.helpers.FileOutput object at 0x7f77363dbd30>, <replicate.helpers.FileOutput object at 0x7f77363d9480>]\n",
            "Negative Prompt: No buildings, Output URLs: ['https://replicate.delivery/yhqm/wHjeaMHyCG28Rq92eSYAJMafAb9hHfrD7cB4JQxgyTd2hvNPB/out-0.png', 'https://replicate.delivery/yhqm/sseSa7VVs40pACj5ZYuS7IpfFzpAY7Mruny77i7mdUtd4bzTA/out-1.png', 'https://replicate.delivery/yhqm/guKdNlYiZ9rUMRGmRI71KCKZAfl8Ncz4f0AfTufIx8Q1hvNPB/out-2.png', 'https://replicate.delivery/yhqm/H1tcTXQXsXr3KJGl5EaGKIwnFqgXssaoefNtfaXRgNa7w3mnA/out-3.png']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I think the affects are limited. But there will be more details."
      ],
      "metadata": {
        "id": "u2jF2fYaqXLe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q3.3"
      ],
      "metadata": {
        "id": "xXaZIUFWqMTI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fixed positive prompt\n",
        "positive_prompt = \"A magical forest with glowing trees\"\n",
        "\n",
        "# Guidance scale values to explore\n",
        "guidance_scales = [5, 10, 15, 20]\n",
        "num_images = 4\n",
        "outputs = []\n",
        "\n",
        "# Generate images for each guidance scale\n",
        "for scale in guidance_scales:\n",
        "    combined_prompt = f\"{positive_prompt}, guidance scale: {scale}\"\n",
        "\n",
        "    try:\n",
        "        # Generate images using replicate_run\n",
        "        output_urls, title, total_time, average_time = replicate_run(bytedance_model, combined_prompt, num_images)\n",
        "        print(f\"Guidance Scale: {scale}, Output URLs: {output_urls}\")\n",
        "\n",
        "        if output_urls:\n",
        "            outputs.append((output_urls, f\"{title} - Guidance Scale: {scale}\", total_time, average_time))\n",
        "        else:\n",
        "            print(f\"No images generated for guidance scale: {scale}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating images for guidance scale {scale}: {e}\")\n",
        "\n",
        "# Display results\n",
        "if outputs:\n",
        "    display_images(outputs)\n",
        "else:\n",
        "    print(\"No images were generated.\")\n"
      ],
      "metadata": {
        "id": "YJ-NpMWMqPqR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11496cd7-1d8e-4f53-b1e2-ff493983db74"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw output: [<replicate.helpers.FileOutput object at 0x7f77366865c0>, <replicate.helpers.FileOutput object at 0x7f774fd0f370>, <replicate.helpers.FileOutput object at 0x7f773664ddb0>, <replicate.helpers.FileOutput object at 0x7f773664f040>]\n",
            "Guidance Scale: 5, Output URLs: ['https://replicate.delivery/yhqm/DyxPtHMbpTZePyxfTP0g259j0KIkNaeQWn2USTi3meoVivNPB/out-0.png', 'https://replicate.delivery/yhqm/ccemd1SeItkHt0WibxkktPg2k8S52VnPf8JtH7fPOFPWivNPB/out-1.png', 'https://replicate.delivery/yhqm/WNgr5g3KuI4iDZuozWhfWednkgXX8dxFKd98MW9uTjEl4bzTA/out-2.png', 'https://replicate.delivery/yhqm/t4SKfwf450iZNkQav38oDHxTOMdEACFEbXfpDSXyqWcKx3mnA/out-3.png']\n",
            "Raw output: [<replicate.helpers.FileOutput object at 0x7f77363da500>, <replicate.helpers.FileOutput object at 0x7f77363d9750>, <replicate.helpers.FileOutput object at 0x7f77363da170>, <replicate.helpers.FileOutput object at 0x7f77363d9480>]\n",
            "Guidance Scale: 10, Output URLs: ['https://replicate.delivery/yhqm/1smdPW8ieBQ4VCDj8RWMfpDjWDbOjSOjuWttarQfnONVx3mnA/out-0.png', 'https://replicate.delivery/yhqm/cuD9etfzthigGEzThZn9ydycMs0net6fXKfsLAs9o4nSFf28E/out-1.png', 'https://replicate.delivery/yhqm/d90ZeaeIloiFl0OrTSsazxNAB63mBwvidlklJI6SeH1Ux3mnA/out-2.png', 'https://replicate.delivery/yhqm/ct1MOei6UPRoAKu3Jd4Gca6KO0QlTiz8bSbPE8f1Pgjq4bzTA/out-3.png']\n",
            "Raw output: [<replicate.helpers.FileOutput object at 0x7f77363d97e0>, <replicate.helpers.FileOutput object at 0x7f77363db5b0>, <replicate.helpers.FileOutput object at 0x7f77363dbdf0>, <replicate.helpers.FileOutput object at 0x7f77363d9600>]\n",
            "Guidance Scale: 15, Output URLs: ['https://replicate.delivery/yhqm/9BDf8shfZ4lxX00xUffSUEnYsEC8XC3a4LxeqtA71eqyLet5JA/out-0.png', 'https://replicate.delivery/yhqm/epfUY82nt4o1g0iNQd3Mz9VDiaJFgt8ebqz4Agzkwe18ivNPB/out-1.png', 'https://replicate.delivery/yhqm/0L9hFwdfgZy1Oq2ta5sJhneznZRHshYJBbfJvNuk7crfivNPB/out-2.png', 'https://replicate.delivery/yhqm/LtsBDCJLGnYoO96nGEAyagIhfvqWVuf33GkAMtrpNzKv4bzTA/out-3.png']\n",
            "Raw output: [<replicate.helpers.FileOutput object at 0x7f77366842b0>, <replicate.helpers.FileOutput object at 0x7f7736684e50>, <replicate.helpers.FileOutput object at 0x7f7736685600>, <replicate.helpers.FileOutput object at 0x7f7736685fc0>]\n",
            "Guidance Scale: 20, Output URLs: ['https://replicate.delivery/yhqm/AUml1gpj7VZAP9Eo7UVg1GCN3fJ6rO4SKetPvwpX18104bzTA/out-0.png', 'https://replicate.delivery/yhqm/0F94ZTijz66bLxx8ARLQA6voYy6ZznkT9bAfYecWXUepx3mnA/out-1.png', 'https://replicate.delivery/yhqm/Z4NunfNavW0zGqXsfPY3yHE6dwBPF8sfR4ZmgETdue4SjvNPB/out-2.png', 'https://replicate.delivery/yhqm/PuO1rNuMTDpiHxAeZZ6PqFXUPRnP5KLeeq5aAm0QsPgpx3mnA/out-3.png']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using a fixed positive prompt, \"A futuristic city at night,\" and experimenting with four negative prompts (\"No bright lights,\" \"No humans,\" \"No technology,\" \"No buildings\"), I observed significant changes in the model's outputs. For \"No bright lights,\" the vibrant neon lighting was subdued, creating a darker, moodier scene. \"No humans\" resulted in desolate cityscapes with an eerie atmosphere, emphasizing architecture and lighting. \"No technology\" shifted the focus to more natural or classical elements, transforming the futuristic city into a timeless environment. Lastly, \"No buildings\" produced open skies and abstract landscapes, removing urban structures entirely. These observations highlight how effectively negative prompts refine outputs, allowing for creative control and exploration in generating diverse visual interpretations."
      ],
      "metadata": {
        "id": "nX8k9LrTqcra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q3.4"
      ],
      "metadata": {
        "id": "IMxdsoWCqfPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Insert your code here\n",
        "# Fixed positive prompt\n",
        "positive_prompt = \"A serene landscape with mountains and a lake\"\n",
        "\n",
        "# Inference step values to explore\n",
        "inference_steps = [10, 25, 50, 100]\n",
        "num_images = 4\n",
        "outputs = []\n",
        "\n",
        "# Generate images for each inference step value\n",
        "for steps in inference_steps:\n",
        "    combined_prompt = f\"{positive_prompt}, inference steps: {steps}\"\n",
        "\n",
        "    try:\n",
        "        # Generate images using replicate_run\n",
        "        output_urls, title, total_time, average_time = replicate_run(bytedance_model, combined_prompt, num_images)\n",
        "        print(f\"Inference Steps: {steps}, Output URLs: {output_urls}\")\n",
        "\n",
        "        if output_urls:\n",
        "            outputs.append((output_urls, f\"{title} - Inference Steps: {steps}\", total_time, average_time))\n",
        "        else:\n",
        "            print(f\"No images generated for inference steps: {steps}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating images for inference steps {steps}: {e}\")\n",
        "\n",
        "# Display results\n",
        "if outputs:\n",
        "    display_images(outputs)\n",
        "else:\n",
        "    print(\"No images were generated.\")\n"
      ],
      "metadata": {
        "id": "Nn-THzWgqhMU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f8c0354-15b4-4f03-8675-76a20e0d3e76"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw output: [<replicate.helpers.FileOutput object at 0x7f773664c1c0>, <replicate.helpers.FileOutput object at 0x7f77365016c0>, <replicate.helpers.FileOutput object at 0x7f77365026b0>, <replicate.helpers.FileOutput object at 0x7f7736501a50>]\n",
            "Inference Steps: 10, Output URLs: ['https://replicate.delivery/yhqm/RibgISOiVzauC1eTbBwvSkuu7aBQ4dwmj5kb6OlXBtGaOu5JA/out-0.png', 'https://replicate.delivery/yhqm/wHVStKYyAwrjAxHYjwTa4flH53yUwM1vlrG1WD8SuOTaOu5JA/out-1.png', 'https://replicate.delivery/yhqm/mWgEv5DueflXd0aNMicTG93uXpkOoeege6lWV2iEeoPANH38E/out-2.png', 'https://replicate.delivery/yhqm/6flUOqY2CJSoXqjPw9UZicPRXqEEwZwItMMzlhuLEbKaOu5JA/out-3.png']\n",
            "Raw output: [<replicate.helpers.FileOutput object at 0x7f774fd0dea0>, <replicate.helpers.FileOutput object at 0x7f774fd0dc90>, <replicate.helpers.FileOutput object at 0x7f774fd0dab0>, <replicate.helpers.FileOutput object at 0x7f774fe39240>]\n",
            "Inference Steps: 25, Output URLs: ['https://replicate.delivery/yhqm/f8FKa6fhiMqxLkQ46kgalz8uO2FmzNyNDItdnMUu2Z79cczTA/out-0.png', 'https://replicate.delivery/yhqm/1dt9lHhrtWYtAhJ5kovmBE28zouxyg5ZUdZrp2cloZYPH38E/out-1.png', 'https://replicate.delivery/yhqm/8GgZ0NfehAixbEQqV2NxeeBZHBWkEEDh6YfOb0X0iIxtnjbeE/out-2.png', 'https://replicate.delivery/yhqm/AvZ4hNhdd9rjPFfuZWpEimtMFf8gsTFVf4rz0BwIaB4654mnA/out-3.png']\n",
            "Raw output: [<replicate.helpers.FileOutput object at 0x7f77363dbe20>, <replicate.helpers.FileOutput object at 0x7f77363dae60>, <replicate.helpers.FileOutput object at 0x7f77363d9960>, <replicate.helpers.FileOutput object at 0x7f77363dad10>]\n",
            "Inference Steps: 50, Output URLs: ['https://replicate.delivery/yhqm/Dgqy0k7eAEQpB6AIYY5OyD7LoXWIwacuhWmoWQtZpwUiOu5JA/out-0.png', 'https://replicate.delivery/yhqm/YReRjnjLgz1uYa4rkIOfBOUotov1BDer0sEeV4ODEoGR0xNPB/out-1.png', 'https://replicate.delivery/yhqm/vv1DGbFwk15JJlmIfWD977Q0WbGiJK1IjxSEDfJDdTeI64mnA/out-2.png', 'https://replicate.delivery/yhqm/1GofQnG9AOWzCKkA3u0feQlK8N7Gq6dNZlPU1reo2EhT0xNPB/out-3.png']\n",
            "Raw output: [<replicate.helpers.FileOutput object at 0x7f77363db3a0>, <replicate.helpers.FileOutput object at 0x7f77363db070>, <replicate.helpers.FileOutput object at 0x7f77363dafb0>, <replicate.helpers.FileOutput object at 0x7f77363db0d0>]\n",
            "Inference Steps: 100, Output URLs: ['https://replicate.delivery/yhqm/dUemieNeXtODKoSOttKzCkOWSLdUjxJPEHo2TboSkH4W64mnA/out-0.png', 'https://replicate.delivery/yhqm/DJFwfiucnwRkDifvHehKb5u36KrMJ0wO1z3fNEfgS7RdpjbeE/out-1.png', 'https://replicate.delivery/yhqm/q74Ipu6Ad6KFLB6WgJeMajC0P9P8JUbtI4x0X8UMJBhlOu5JA/out-2.png', 'https://replicate.delivery/yhqm/Xw99mFIuMT5IJ5nXbEWlopMvHx4SKGc6ppdsOT0QF43SH38E/out-3.png']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The number of inference steps has a clear impact on the model’s output quality, variety, and runtime. Lower inference steps (e.g., 10) prioritize speed and creativity, producing diverse but less refined outputs with visible artifacts. Moderate steps (e.g., 25) strike a good balance between quality and runtime, offering detailed and visually appealing images while retaining some variation. Higher steps (e.g., 50) improve image quality further, with intricate details and textures, but reduce diversity. Very high steps (e.g., 100) provide minimal improvement in quality at the cost of significantly increased runtime and near-identical outputs. In practice, a moderate number of steps (e.g., 25–50) is ideal for achieving high-quality outputs efficiently, while higher steps may only be necessary for highly specific use cases requiring perfect adherence to the prompt."
      ],
      "metadata": {
        "id": "j0Z2pPB0qi-b"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}